{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3f5920-992d-4ffd-813f-506a61cf8977",
   "metadata": {},
   "source": [
    "# KNN Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea85464-48e2-46af-b99d-f2fb6664cac3",
   "metadata": {},
   "source": [
    "### Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?"
   ]
  },
  {
   "attachments": {
    "8ccf951b-20e4-468a-b4c0-c5a3e49a6539.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "id": "0ee35594-06a8-4795-9bac-8289861f1f73",
   "metadata": {},
   "source": [
    "\n",
    "**Euclidean Distance:**\n",
    "\n",
    "| Aspect                  | Description                                          |\n",
    "|-------------------------|------------------------------------------------------|\n",
    "| Formula                 | `sqrt((x1-x2)^2 + (y1-y2)^2 + (z1-z2)^2 + ...)`     |\n",
    "| Sensitivity             | Sensitive to both magnitude and direction.           |\n",
    "| Anisotropy              | Suitable for isotropic (similar in all directions) relationships between features. |\n",
    "\n",
    "**Manhattan Distance:**\n",
    "\n",
    "| Aspect                  | Description                                          |\n",
    "|-------------------------|------------------------------------------------------|\n",
    "| Formula                 | absolute values : x1-x2 + y1-y2 + z1-z2 + ...             |\n",
    "| Sensitivity             | Less sensitive to outliers and differences in scale.  |\n",
    "| Anisotropy              | Suitable for anisotropic (differing in various directions) relationships between features. |\n",
    "\n",
    "**How might this difference affect the performance of a KNN classifier or regressor?**\n",
    "\n",
    "![download.jpg](attachment:8ccf951b-20e4-468a-b4c0-c5a3e49a6539.jpg)\n",
    " \n",
    "**Euclidean Distance**:\n",
    "\n",
    "- Imagine it's like measuring the straight-line distance between two points. It cares about both how far apart they are and in which direction they are separated.\n",
    "\n",
    "- It can be sensitive to differences in scale (like comparing meters to millimeters) and can be affected by outliers (unusual data points).\n",
    "\n",
    "- Use it when your data's relationships between features are similar in all directions, like measuring distances in a balanced way.\n",
    "\n",
    "**Manhattan Distance**:\n",
    "\n",
    "- Think of it as measuring the distance by adding up the steps you need to take when moving in a grid-like city. It only considers how many steps you take in different directions.\n",
    "\n",
    "- It's less sensitive to differences in scale and outliers because it only looks at the absolute differences (ignoring plus or minus) along each axis.\n",
    "\n",
    "- Use it when your data's relationships between features are different in various directions, like navigating a city with lots of right-angle turns.\n",
    "\n",
    "In KNN, choosing the right one depends on your data. If your data is balanced and has similar relationships between features, go for Euclidean. If it's not balanced or has different relationships, go for Manhattan. And remember, sometimes it's best to try both and see which one works better for your specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a1242-9d54-4c83-95e9-1c87374ff73a",
   "metadata": {},
   "source": [
    "### Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be used to determine the optimal k value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4041c92-465e-4fff-9aa8-ce300ce2c046",
   "metadata": {},
   "source": [
    "1. **Odd vs. Even K**:\n",
    "   - For a binary classification problem (two classes), it's better to choose an odd K value to prevent ties when voting for the class, making predictions less ambiguous.\n",
    "\n",
    "2. **Cross-Validation**:\n",
    "   - A reliable way to find the right K is by splitting your data into training and validation sets and testing different K values. Pick the K that gives the best performance on the validation data, which helps prevent overfitting.\n",
    "\n",
    "3. **Domain Knowledge**:\n",
    "   - If you know your problem well, consider your domain knowledge when selecting K. It can provide valuable insights into what neighborhood size is most meaningful for your specific application.\n",
    "\n",
    "4. **Rule of Thumb**:\n",
    "   - As a starting point, you can use K = sqrt(N), where N is the total number of data points in your dataset. It's a reasonable initial choice for K."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b035f4-204f-45b9-9afa-3d866e03bc76",
   "metadata": {},
   "source": [
    "### Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In what situations might you choose one distance metric over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f8f5e-7480-4117-b76b-77f38481fdad",
   "metadata": {},
   "source": [
    "\n",
    "- **Euclidean Distance** is like measuring distance in a straight line. It's great when everything is balanced and you care about both how far apart things are and in what direction they're separated. It's sensitive to differences in size and can be affected by unusual data.\n",
    "\n",
    "- **Manhattan Distance** is like measuring distance by counting steps in a city with streets running north-south and east-west. It works better when things are not balanced, and you don't really care about size or direction as much. It's less bothered by unusual data.\n",
    "\n",
    "- **Choosing the Right One**: Use Euclidean when things are balanced and both size and direction matter. Use Manhattan when things are not balanced, and you don't care as much about size or direction. Sometimes, it's good to try both and see what works best for your specific problem.\n",
    "\n",
    "- If you have a lot of data with many features, you might want to think about reducing the number of features, so you don't get bogged down by the calculations. This is especially important when dealing with high-dimensional data.\n",
    "\n",
    "In a nutshell, the choice between Euclidean and Manhattan distance depends on the nature of your data. One might work better than the other depending on how balanced your data is and whether you care more about size or direction. Experiment to see which one gives you better results for your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af30326-41dc-4a69-b5dd-47f714810f42",
   "metadata": {},
   "source": [
    "### Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect the performance of the model? How might you go about tuning these hyperparameters to improve model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f7da6b-7c0e-4ff9-8eb7-5d5ca27b939a",
   "metadata": {},
   "source": [
    "\n",
    "| Hyperparameter          | Effect on Performance                               | Tuning Strategy                                        |\n",
    "|------------------------|----------------------------------------------------|--------------------------------------------------------|\n",
    "| K (Number of Neighbors) | - Smaller K: Sensitive to noise, potential overfitting - Larger K: Oversmoothing | Use cross-validation or grid search to experiment with different K values and choose the one that minimizes errors. |\n",
    "| Distance Metric        | - Affects similarity calculation (e.g., Euclidean, Manhattan) - Should match data characteristics | Experiment with different distance metrics to choose the one that works best for your dataset based on scale and direction. |\n",
    "| Weighting Scheme       | - Uniform (all neighbors have equal weight) - Distance-based (closer neighbors have more influence) | Experiment with different weighting schemes to see which one yields better results. Distance-based weighting can be beneficial when closer neighbors are more informative. |\n",
    "| Algorithm for Finding Neighbors | - Different algorithms (e.g., Ball Tree, KD Tree) - Impact computational efficiency | Depending on dataset size and dimensionality, test different neighbor search algorithms to find the one that works faster and more effectively. |\n",
    "| Dimensionality Reduction | - Reduces the number of features - Addresses \"curse of dimensionality\" | Experiment with dimensionality reduction techniques, like PCA, to reduce high-dimensional data's complexity. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee672dd-9c66-4a56-971a-4d572cdeea97",
   "metadata": {},
   "source": [
    "### Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What techniques can be used to optimize the size of the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e385aa-cd3e-437f-a815-99c7e489ef98",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Training Set Size     | Small Training Set                                                                                              | Large Training Set                                                                                     |\n",
    "|-----------------------|------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|\n",
    "| Effect on Performance | - The model may not capture underlying patterns effectively. - Sensitivity to noise and high variance, leading to overfitting. | - More data to learn from, capturing true underlying patterns. - Reduced risk of overfitting.          |\n",
    "| Issues                | - Overfitting - Poor generalization to unseen data - Unreliable model predictions                                       |  - Better overall performance - Computational complexity - Data management challenges - Handling outliers and noise - Curse of dimensionality - Generalization to unseen data - Model complexity                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9fd408-6124-48ef-8623-ef1baf290216",
   "metadata": {},
   "source": [
    "Optimizing the size of the training set in a K-Nearest Neighbors (KNN) model involves strategies to make the most of the available data. Here are techniques that can be used to optimize the training set size:\n",
    "\n",
    "1. **Data Collection**:\n",
    "   - Collect more data: If possible, gather additional data from various sources to increase the size of your training set.\n",
    "\n",
    "2. **Data Sampling**:\n",
    "   - Bootstrapping: Generate additional training examples by resampling from your existing data with replacement.\n",
    "   - Random sampling: Randomly select a subset of your data for training, creating a smaller but diverse training set.\n",
    "\n",
    "3. **Feature Selection**:\n",
    "   - Carefully choose the most informative features to include in your training set. Removing irrelevant or redundant features can effectively reduce the dimensionality of your data.\n",
    "\n",
    "4. **Dimensionality Reduction**:\n",
    "   - Use dimensionality reduction techniques like Principal Component Analysis (PCA) to reduce the number of features while preserving important information.\n",
    "\n",
    "5. **Data Augmentation**:\n",
    "   - Create synthetic data by applying domain knowledge or data augmentation techniques. For instance, in image classification, you can rotate, crop, or flip existing images to generate more training examples.\n",
    "\n",
    "6. **Cross-Validation**:\n",
    "   - Implement cross-validation techniques (e.g., k-fold cross-validation) to make more efficient use of your existing data. Cross-validation divides your data into training and validation sets multiple times, helping you assess your model's performance more accurately.\n",
    "\n",
    "7. **Active Learning**:\n",
    "   - Use active learning strategies to intelligently select which data points to label and include in the training set, focusing on the most informative examples.\n",
    "\n",
    "8. **Incremental Learning**:\n",
    "   - Implement incremental or online learning techniques, where you continuously update your model as new data becomes available. This can be useful for adapting to changing data distributions.\n",
    "\n",
    "9. **Weighted Sampling**:\n",
    "   - If certain subsets of your data are more representative or valuable, use weighted sampling to increase the prominence of those subsets in your training data.\n",
    "\n",
    "10. **Domain Knowledge**:\n",
    "    - Leverage domain expertise to curate a more focused training set that captures the most important aspects of your problem.\n",
    "\n",
    "11. **Synthetic Data Generation**:\n",
    "    - For imbalanced datasets, generate synthetic data for minority classes to balance the training set.\n",
    "\n",
    "12. **Data Imputation**:\n",
    "    - Use data imputation techniques to fill in missing values and make the most of incomplete data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb912b7-06b9-4bc1-8ef7-891db44bf53d",
   "metadata": {},
   "source": [
    "### Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you overcome these drawbacks to improve the performance of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db74a272-795a-46dd-adc2-3be428ebcac9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Drawback                         | How to Overcome                               |\n",
    "|----------------------------------|-----------------------------------------------|\n",
    "| Computational Intensity          | Use efficient data structures (e.g., KD-trees or Ball trees) for faster neighbor search. |\n",
    "| Curse of Dimensionality          | Apply dimensionality reduction techniques like PCA to reduce the number of features. |\n",
    "| Sensitivity to Scale and Outliers | Scale and standardize features to make them comparable and reduce sensitivity to scale and outliers. |\n",
    "| Local Optima                     | Experiment with different values of K and distance metrics using cross-validation or grid search. |\n",
    "| Ineffective for Imbalanced Data  | Use resampling techniques (e.g., oversampling, undersampling, or synthetic data generation) to address imbalanced datasets. |\n",
    "| Memory Usage                     | Optimize memory usage and consider using parallel processing for large datasets. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad835120-7f2a-47fc-81c9-5b5713f376e9",
   "metadata": {},
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
